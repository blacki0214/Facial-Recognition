{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":22881,"databundleVersionId":1552852,"sourceType":"competition"}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os, time, random, shutil\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense, BatchNormalization, Input, Concatenate\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom sklearn.metrics import roc_auc_score, roc_curve\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# GPU setup\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # use only one GPU\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    for gpu in gpus:\n        tf.config.experimental.set_memory_growth(gpu, True)\nprint(\"GPU ready:\", gpus)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T13:13:23.845265Z","iopub.execute_input":"2025-11-10T13:13:23.845768Z","iopub.status.idle":"2025-11-10T13:13:23.851732Z","shell.execute_reply.started":"2025-11-10T13:13:23.845744Z","shell.execute_reply":"2025-11-10T13:13:23.851106Z"}},"outputs":[{"name":"stdout","text":"GPU ready: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"root_path = \"/kaggle/input/11-785-fall-20-homework-2-part-2\"\ntrain_dir = f\"{root_path}/classification_data/train_data\"\nval_dir   = f\"{root_path}/classification_data/val_data\"\n\n# Create smaller subset for faster training\ndef create_subset(src, dst, limit_per_class=60):\n    os.makedirs(dst, exist_ok=True)\n    for cls in os.listdir(src):\n        src_cls = os.path.join(src, cls)\n        dst_cls = os.path.join(dst, cls)\n        if not os.path.isdir(src_cls): continue\n        os.makedirs(dst_cls, exist_ok=True)\n        imgs = os.listdir(src_cls)\n        for img in random.sample(imgs, min(limit_per_class, len(imgs))):\n            shutil.copy(os.path.join(src_cls, img), os.path.join(dst_cls, img))\n\nif not os.path.exists(\"/kaggle/working/train_subset\"):\n    create_subset(train_dir, \"/kaggle/working/train_subset\", 60)\n    create_subset(val_dir, \"/kaggle/working/val_subset\", 20)\n\ntrain_dir = \"/kaggle/working/train_subset\"\nval_dir   = \"/kaggle/working/val_subset\"\n\nimg_size = (160,160)\nbatch_size = 32\n\ntrain_gen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=10,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True\n).flow_from_directory(train_dir, target_size=img_size, batch_size=batch_size, class_mode='categorical')\n\nval_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(\n    val_dir, target_size=img_size, batch_size=batch_size, class_mode='categorical')\n\nnum_classes = train_gen.num_classes\nprint(\"Classes:\", num_classes)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T13:13:23.852894Z","iopub.execute_input":"2025-11-10T13:13:23.853130Z","iopub.status.idle":"2025-11-10T13:13:28.927916Z","shell.execute_reply.started":"2025-11-10T13:13:23.853114Z","shell.execute_reply":"2025-11-10T13:13:28.927294Z"}},"outputs":[{"name":"stdout","text":"Found 233470 images belonging to 4000 classes.\nFound 8000 images belonging to 4000 classes.\nClasses: 4000\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Build EfficientNetB0\nbase = EfficientNetB0(weights='imagenet', include_top=False, input_shape=img_size+(3,))\n\n# Freeze earlier layers, fine-tune last 80\nfor layer in base.layers[:-80]:\n    layer.trainable = False\n\nx = GlobalAveragePooling2D()(base.output)\nx = BatchNormalization()(x)\nx = Dropout(0.4)(x)\noutput = Dense(num_classes, activation='softmax', dtype='float32')(x)\nsoftmax_model = Model(inputs=base.input, outputs=output)\n\nopt = tf.keras.optimizers.Adam(learning_rate=1e-4)\nsoftmax_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n\ncallbacks = [\n    EarlyStopping(patience=1, restore_best_weights=True),\n    ReduceLROnPlateau(patience=1, factor=0.5, min_lr=1e-6)\n]\n\nstart = time.time()\nhistory = softmax_model.fit(train_gen, validation_data=val_gen, epochs=8, callbacks=callbacks)\nprint(\"⏱ Training finished in\", round((time.time()-start)/60,1), \"minutes\")\n\nsoftmax_model.save(\"/kaggle/working/softmax_model.keras\")\nprint(\"Saved softmax_model.keras\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T13:13:28.928604Z","iopub.execute_input":"2025-11-10T13:13:28.928835Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/8\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1762780443.837220     116 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1762780443.974571     116 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m3473/7296\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m10:58\u001b[0m 172ms/step - accuracy: 3.6839e-04 - loss: 8.5702","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"embedding_model = Model(inputs=softmax_model.input, outputs=softmax_model.layers[-2].output)\nembedding_model.save(\"/kaggle/working/embedding_model.keras\")\nprint(\"Saved embedding_model.keras\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pairs = pd.read_csv(f\"{root_path}/verification_pairs_val.txt\", sep=\" \", header=None, names=[\"img1\",\"img2\",\"label\"])\n\ndef preprocess(img_path):\n    img = tf.keras.preprocessing.image.load_img(img_path, target_size=img_size)\n    arr = tf.keras.preprocessing.image.img_to_array(img)/255.\n    return np.expand_dims(arr, axis=0)\n\ndef embed_image(path):\n    return embedding_model.predict(preprocess(path), verbose=0).squeeze()\n\ndef cosine_sim(a,b):\n    return np.dot(a,b)/(np.linalg.norm(a)*np.linalg.norm(b))\n\ndef euclid_sim(a,b):\n    return -np.linalg.norm(a-b)\n\ncos_scores, euc_scores, labels = [], [], []\n\nfor _, r in pairs.iterrows():\n    img1 = os.path.join(root_path, r.img1)\n    img2 = os.path.join(root_path, r.img2)\n    emb1, emb2 = embed_image(img1), embed_image(img2)\n    cos_scores.append(cosine_sim(emb1, emb2))\n    euc_scores.append(euclid_sim(emb1, emb2))\n    labels.append(r.label)\n\nauc_cos = roc_auc_score(labels, cos_scores)\nauc_euc = roc_auc_score(labels, euc_scores)\nprint(\"AUC (Cosine):\", round(auc_cos,4))\nprint(\"AUC (Euclidean):\", round(auc_euc,4))\n\n# Plot ROC Curve\nfpr, tpr, _ = roc_curve(labels, cos_scores)\nplt.plot(fpr, tpr, label=f\"Cosine AUC={auc_cos:.4f}\")\nplt.plot([0,1], [0,1], 'k--')\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"ROC Curve - Face Verification\")\nplt.legend()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def triplet_loss(y_true, y_pred, alpha=0.2):\n    total_leng = y_pred.shape[-1] // 3\n    a, p, n = y_pred[:, :total_leng], y_pred[:, total_leng:2*total_leng], y_pred[:, 2*total_leng:]\n    pos_dist = tf.reduce_sum(tf.square(a-p), axis=1)\n    neg_dist = tf.reduce_sum(tf.square(a-n), axis=1)\n    return tf.reduce_mean(tf.maximum(pos_dist - neg_dist + alpha, 0.0))\n\ninput_a = Input(shape=img_size+(3,))\ninput_p = Input(shape=img_size+(3,))\ninput_n = Input(shape=img_size+(3,))\n\nemb_a = embedding_model(input_a)\nemb_p = embedding_model(input_p)\nemb_n = embedding_model(input_n)\nmerged = Concatenate(axis=1)([emb_a, emb_p, emb_n])\n\ntriplet_model = Model([input_a, input_p, input_n], merged)\ntriplet_model.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss=triplet_loss)\ntriplet_model.save(\"/kaggle/working/triplet_model.keras\")\nprint(\"Saved triplet_model.keras (structure ready for fine-tuning)\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pairs_test = pd.read_csv(f\"{root_path}/verification_pairs_test.txt\", sep=\" \", header=None, names=[\"img1\",\"img2\"])\nscores_test = []\n\nfor _, r in pairs_test.iterrows():\n    img1 = os.path.join(root_path, r.img1)\n    img2 = os.path.join(root_path, r.img2)\n    emb1, emb2 = embed_image(img1), embed_image(img2)\n    scores_test.append(cosine_sim(emb1, emb2))\n\nsubmission = pd.DataFrame({\n    \"pair\": [f\"{r.img1} {r.img2}\" for _, r in pairs_test.iterrows()],\n    \"score\": scores_test\n})\nsubmission.to_csv(\"/kaggle/working/hw2p2_submission.csv\", index=False)\nprint(\"Generated submission file: hw2p2_submission.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}